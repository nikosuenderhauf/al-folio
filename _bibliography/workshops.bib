
@inproceedings{nicholson2018quadricslam,
  title={{QuadricSLAM: Constrained Dual Quadrics from Object Detections as Landmarks in Semantic SLAM}},
  author={Nicholson, Lachlan and Milford, Michael and S{\"u}nderhauf, Niko},
  booktitle = {{Workshop on Representing a Complex World, International Conference on Robotics and Automation (ICRA)}},
  year={2018},
  link = {https://arxiv.org/abs/1804.04011},
  abstract = {We derive a SLAM formulation that uses dual quadrics as 3D landmark representations, exploiting their ability to compactly represent the size, position and orientation of an object, and show how 2D bounding boxes (such as those typically obtained from visual object detection systems) can directly constrain the quadric parameters via a novel geometric error formulation. We develop a sensor model for deep-learned object detectors that addresses the challenge of partial object detections often encountered in robotics applications, and demonstrate how to jointly estimate the camera pose and constrained dual quadric parameters in factor graph based SLAM with a general perspective camera.},
  thumb={nicholson18quadricslam.png},
  award={Best Workshop Paper Award}
}

@inproceedings{Miller17a,
  title={{Dropout Variational Inference Improves Object Detection in Open-Set Conditions}},
  author={Dimity Miller and Lachlan Nicholson and Feras Dayoub and Niko S\"underhauf},
  year={2017},
  booktitle = {{Proc. of NIPS Workshop on Bayesian Deep Learning}},
  status = {workshop},
  link={http://bayesiandeeplearning.org/2017/papers/20.pdf},
  abstract={Here we extend the concept of Dropout sampling to object detection for the first time. We evaluate
Bayesian object detection on a large synthetic and a real-world dataset and show how the estimated
label uncertainty can be utilized to increase object detection performance under open-set conditions.},
  thumb={miller17dropout.png}
}

@inproceedings{Dayoub17,
  title={{Episode-Based Active Learning with Bayesian Neural Networks}},
  author={Dayoub, Feras and S\"underhauf, Niko and Corke, Peter},
  booktitle={Workshop on Deep Learning for Robotic Vision, Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2017},
  status = {workshop},
  link={http://openaccess.thecvf.com/content_cvpr_2017_workshops/w5/papers/Dayoub_Episode-Based_Active_Learning_CVPR_2017_paper.pdf},
  abstract={We investigate different strategies for active learning
with Bayesian deep neural networks. We focus our analysis
on scenarios where new, unlabeled data is obtained episodically,
such as commonly encountered in mobile robotics
applications. An evaluation of different strategies for acquisition,
updating, and final training on the CIFAR-10 dataset
shows that incremental network updates with final training
on the accumulated acquisition set are essential for best
performance, while limiting the amount of required human
labeling labor.},
thumb={dayoub17active.png}
}

@inproceedings{Bruce17,
  title={{One-Shot Reinforcement Learning for Robot Navigation with Interactive Replay}},
  author={Jacob Bruce and Niko S\"underhauf and Piotr Mirowski and Raia Hadsell and Michael Milford},
  year={2017},
  booktitle = {{Proc. of NIPS Workshop on Acting and Interacting in the Real World: Challenges in Robot Learning}},
  status = {workshop},
  link={https://arxiv.org/abs/1711.10137},
  abstract={Recently, model-free reinforcement learning algorithms have been shown to solve challenging problems by learning from extensive interaction with the environment. A significant issue with transferring this success to the robotics domain is that interaction with the real world is costly, but training on limited experience is prone to overfitting. We present a method for learning to navigate, to a fixed goal and in a known environment, on a mobile robot. The robot leverages an interactive world model built from a single traversal of the environment, a pre-trained visual feature encoder, and stochastic environmental augmentation, to demonstrate successful zero-shot transfer under real-world environmental variations without fine-tuning.},
  thumb={bruce17navigation.png}
}

@inproceedings{Milford15,
  title={{Sequence Searching with Deep-learnt Depth for Condition-and Viewpoint-invariant Route-based Place Recognition}},
  author={Milford, Michael and Lowry, Stephanie and S\"underhauf, Niko and Shirazi, Sareh and Pepperell, Edward and Upcroft, Ben and Shen, Chunhua and Lin, Guosheng and Liu, Fayao and Cadena, Cesar and others},
  booktitle={WorksPeterohop on Computer Vision in Vehicle Technology (CVVT), Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2015}
}


@INPROCEEDINGS{Suenderhauf15b,
  author = {Niko S\"underhauf and Ben Upcroft and Michael Milford},
  title = {{Continuous Factor Graphs For Holistic Scene Understanding}},
  booktitle = {Workshop on Scene Understanding (SUNw), Intl. Conf. on Computer Vision and Pattern Recognition (CVPR)},
  year = {2015},
  owner = {niko},
  timestamp = {2015.06.05}
}



@INPROCEEDINGS{McMahon15,
  author = {Sean McMahon and Niko S\"underhauf and Ben Upcroft and Michael Milford},
  title = {{How Good Are EdgeBoxes, Really?}},
  booktitle = {Workshop on Scene Understanding (SUNw), Intl. Conf. on Computer Vision and Pattern Recognition (CVPR)},
  year = {2015},
  owner = {niko},
  timestamp = {2015.06.05}
}


@InProceedings{Suenderhauf15d,
  Title                    = {{SLAM -- Quo Vadis? In Support of Object Oriented and Semantic SLAM}},
  Author                   = {Niko S\"underhauf and Feras Dayoub and Sean McMahon and Markus Eich and Ben Upcroft and Michael Milford},
  Booktitle                = {Workshop on The Problem of Moving Sensors, Robotics: Science and Systems (RSS)},
  Year                     = {2015},

  Owner                    = {niko},
  Timestamp                = {2015.06.05}
}

@inproceedings{sunderhauf2014fine,
  title={Fine-Grained Plant Classification Using Convolutional Neural Networks for Feature Extraction.},
  author={S{\"u}nderhauf, Niko and McCool, Chris and Upcroft, Ben and Perez, Tristan},
  booktitle={CLEF (Working Notes)},
  pages={756--762},
  year={2014}
}

@INPROCEEDINGS{Suenderhauf05b,
  author = {Niko S{\"u}nderhauf and Kurt Konolige and Thomas Lemaire and Simon
    Lacroix},
  title = {{Comparison of Stereovision Odometry Approaches.}},
  booktitle = {Proceedings of IEEE International Conference on Robotics and Automation,
    Planetary Rover Workshop},
  year = {2005}
}


@INPROCEEDINGS{Suenderhauf13d,
  author = {Niko S\"underhauf and Peer Neubert and Peter Protzel},
  title = {{Predicting the Change -- A Step Towards Life-Long Operation in Everyday Environments}},
  booktitle = {Proceedings of Robotics: Science and Systems (RSS) Robotics Challenges
    and Vision Workshop},
  year = {2013},
  owner = {niko},
  timestamp = {2013.07.02},
  link={/assets/papers/rss13Workshop.pdf}
}

@INPROCEEDINGS{Suenderhauf13b,
  author = {S\"underhauf, Niko and Neubert, Peer and Protzel, Peter},
  title = {{Are We There Yet? Challenging SeqSLAM on a 3000 km Journey Across All
    Four Seasons.}},
  booktitle = {Proceedings of Workshop on Long-Term Autonomy, IEEE International
    Conference on Robotics and Automation (ICRA)},
  year = {2013},
  owner = {niko},
  timestamp = {2013.04.29},
  link={/assets/papers/openseqslam.pdf}
}





@INPROCEEDINGS{Suenderhauf12d,
  author = {S{\"u}nderhauf, Niko and Protzel, Peter},
  title = {{A Generic Approach for Robust Probabilistic Estimation with Graphical
    Models}},
  booktitle = {Proc. of RSS Workshop on Long-term Operation of Autonomous Robotic
    Systems in Changing Environments},
  year = {2012},
  address = {Sydney, Australia},
  owner = {niko},
  timestamp = {2012.08.20}
}
