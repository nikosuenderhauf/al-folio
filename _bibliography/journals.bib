
@article{nicholson18quadricslam,
  title={{QuadricSLAM: Constrained Dual Quadrics from Object Detections as Landmarks in Object-oriented SLAM}},
  author={Nicholson, Lachlan and Milford, Michael and S{\"u}nderhauf, Niko},
  booktitle = {{Workshop on Representing a Complex World, International Conference on Robotics and Automation (ICRA)}},
  year={2018},
  journal={IEEE Robotics and Automation Letters (RA-L)},
  year={2018},
  publisher={IEEE},
  link = {https://ieeexplore.ieee.org/document/8440105/},
  abstract = {In this paper, we use 2D object detections from multiple views to simultaneously estimate a 3D quadric surface for each object and localize the camera position. We derive a SLAM formulation that uses dual quadrics as 3D landmark representations, exploiting their ability to compactly represent the size, position and orientation of an object, and show how 2D object detections can directly constrain the quadric parameters via a novel geometric error formulation. We develop a sensor model for object detectors that addresses the challenge of partially visible objects, and demonstrate how to jointly estimate the camera pose and constrained dual quadric parameters in factor graph based SLAM with a general perspective camera.},
  thumb={nicholson18quadricslam.png},
  html={http://semanticslam.ai/quadricslam.html},
  arxiv={1804.04011}
}

@article{sunderhauf2018limits,
  title={The Limits and Potentials of Deep Learning for Robotics},
  author={S{\"u}nderhauf, Niko and Brock, Oliver and Scheirer, Walter and Hadsell, Raia and Fox, Dieter and Leitner, J{\"u}rgen and Upcroft, Ben and Abbeel, Pieter and Burgard, Wolfram and Milford, Michael and others},
  journal={The International Journal of Robotics Research},
  volume={37},
  number={4-5},
  pages={405--420},
  year={2018},
  publisher={SAGE Publications Sage UK: London, England},
  abstract={The application of deep learning in robotics leads
to very specific problems and research questions that are
typically not addressed by the computer vision and machine
learning communities. In this paper we discuss a number
of robotics-specific learning, reasoning, and embodiment challenges
for deep learning. We explain the need for better evaluation
metrics, highlight the importance and unique challenges for
deep robotic learning in simulation, and explore the spectrum
between purely data-driven and model-driven approaches. We
hope this paper provides a motivating overview of important
research directions to overcome the current limitations, and
help fulfill the promising potentials of deep learning in robotics.},
  thumb={suenderhauf18limitsandpotentials.png},
  link={http://journals.sagepub.com/doi/abs/10.1177/0278364918770733},
  arxiv={1804.06557}
}


@article{McMahon17,
  title={{Multi-Modal Trip Hazard Affordance Detection On Construction Sites}},
  author={McMahon, Sean and S\"underhauf, Niko and Upcroft, Ben and Milford, Michael J},
  journal={IEEE Robotics and Automation Letters (RA-L)},
  year={2017},
  publisher={IEEE},
  abstract={Trip hazards are a significant contributor to accidents on construction and manufacturing sites. We conduct a comprehensive investigation into the performance characteristics of 11 different colors and depth fusion approaches, including four fusion and one nonfusion approach, using color and two types of depth images. Trained and tested on more than 600 labeled trip hazards over four floors and 2000 m2 in an active construction site, this approach was able to differentiate between identical objects in different physical configurations. Outperforming a color-only detector, our multimodal trip detector fuses color and depth information to achieve a 4% absolute improvement in F1-score. These investigative results and the extensive publicly available dataset move us one step closer to assistive or fully automated safety inspection systems on construction sites.},
  link={https://ieeexplore.ieee.org/document/7959072/},
  thumb={mcmahon17hazards.png}
}


@article{Lowry15,
  title={{Visual Place Recognition: A Survey}},
  author={Lowry, Stephanie and S\"underhauf, Niko and Newman, Paul and Leonard, John J and Cox, David and Corke, Peter and Milford, Michael J},
  journal={Transactions on Robotics (TRO)},
  year={2015},
  publisher={IEEE},
  link={/assets/papers/visual_place_recognition_a_survey.pdf},
  thumb={lowry15survey.png},
  abstract={This paper presents a survey of the visual place
recognition research landscape. We start by introducing the
concepts behind place recognition – the role of place recognition
in the animal kingdom, how a “place” is defined in a robotics
context, and the major components of a place recognition system.
We then survey visual place recognition solutions for
environments where appearance change is assumed to be
negligible. Long term robot operations have revealed that
environments continually change; consequently we survey place
recognition solutions that implicitly or explicitly account for
appearance change within the environment. Finally we close with
a discussion of the future of visual place recognition, in particular
with respect to the rapid advances being made in the related
fields of deep learning, semantic scene understanding and video
description.}
}

@article{neubert2015superpixel,
  title={Superpixel-based appearance change prediction for long-term navigation across seasons},
  author={Neubert, Peer and S{\"u}nderhauf, Niko and Protzel, Peter},
  journal={Robotics and Autonomous Systems},
  volume={69},
  pages={15--27},
  year={2015},
  publisher={Elsevier},
  link={/assets/papers/ACP_RAS.pdf},
  thumb={neubert15change.png},
  abstract={The goal of our work is to support
existing approaches to place recognition by learning how the
visual appearance of an environment changes over time and by
using this learned knowledge to predict its appearance under
different environmental conditions. We describe the general
idea of appearance change prediction (ACP) and investigate
properties of our novel implementation based on vocabularies
of superpixels (SP-ACP). This paper deepens the
understanding of the proposed SP-ACP system and evaluates
the influence of its parameters. We present the results of a largescale
experiment on the complete 10 hour Nordland dataset and
appearance change predictions between different combinations
of seasons.}
}

@INCOLLECTION{Suenderhauf10,
  author = {S{\"u}nderhauf, Niko and Protzel, Peter},
  title = {{Learning from Nature: Biologically Inspired Robot Navigation and
    SLAM -- A Review}},
  booktitle = {K{\"u}nstliche Intelligenz (German Journal on Artificial Intelligence),
    Special Issue on SLAM},
  publisher = {Springer Verlag},
  year = {2010},
  address = {Heidelberg},
  journal = {K\"unstliche Intelligenz, Special Issue on SLAM, Springer Verlag},
  owner = {niko},
  timestamp = {2010.04.14}
}
