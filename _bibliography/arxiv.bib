---
---




@article{Jablonsky18geometric,
  title={{An Orientation Factor for Object-Oriented SLAM}},
  author={Natalie Jablonsky and Michael Milford and Niko S\"underhauf},
  year={2018},
  journal = {{arXiv preprint}},
  abstract = {Current approaches to object-oriented SLAM lack the ability to incorporate prior knowledge of the scene geometry, such as the expected global orientation of objects. We overcome this limitation by proposing a geometric factor that constrains the global orientation of objects in the map, depending on the objects’ semantics. This new geometric factor is a first example of how semantics can inform and improve geometry in object-oriented SLAM. We implement the geometric factor for the recently proposed QuadricSLAM that represents landmarks as dual quadrics. The factor probabilistically models the quadrics’ major axes to be either perpendicular to or aligned with the direction of gravity, depending on their semantic class. Our experiments on simulated and real-world datasets show that using the proposed factors to incorporate prior knowledge improves both the trajectory and landmark quality.},
link={https://arxiv.org/abs/1809.06977},
thumb={jablonsky18geometric.png},
arxiv={1809.06977},
html={http://semanticslam.ai/geometricfactors.html}
}

@article{Lee18zeroshot,
  title={{Zero-shot Sim-to-Real Transfer with Modular Priors}},
  author={Robert Lee and Serena Mou and Vibhavari Dasagi and Jake Bruce and Jürgen Leitner and Niko S\"underhauf},
  year={2018},
  journal = {{arXiv preprint}},
  abstract = {Current end-to-end Reinforcement Learning (RL) approaches are severely limited by restrictively large search spaces and are prone to overfitting to their training environment. This is because in end-to-end RL perception, decision-making and low-level control are all being learned jointly from very sparse reward signals, with little capability of incorporating prior knowledge or existing algorithms. In this work, we propose a novel framework that effectively decouples RL for high-level decision making from low-level perception and control. This allows us to transfer a learned policy from a highly abstract simulation to a real robot without requiring any transfer learning. We therefore coin our approach zero-shot sim-to-real transfer. We successfully demonstrate our approach on the robot manipulation task of object sorting. A key component of our approach is a deep sets encoder that enables us to reinforcement learn the high-level policy based on the variable-length output of a pre-trained object detector, instead of learning from raw pixels. We show that this method can learn effective policies within mere minutes of highly simplified simulation. The learned policies can be directly deployed on a robot without further training, and generalize to variations of the task unseen during training.},
link={https://arxiv.org/abs/1809.07480},
thumb={lee18zeroshot.png},
arxiv={1809.07480}
}
