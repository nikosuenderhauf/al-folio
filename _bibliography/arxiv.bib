---
---

@article{suenderhauf19keys,
  title={{Where are the Keys? -- Learning Object-Centric Navigation Policies on Semantic Maps with Graph Convolutional Networks}},
  author={S{\"u}nderhauf, Niko},
  journal={arXiv preprint arXiv:1909.07376},
  year={2019},
  abstract={Emerging object-based SLAM algorithms can build a graph representation of an environment comprising nodes for robot poses and object landmarks. However, while this map will contain static objects such as furniture or appliances, many moveable objects (e.g. the car keys, the glasses, or a magazine), are not suitable as landmarks and will not be part of the map due to their non-static nature. We show that Graph Convolutional Networks can learn navigation policies to find such unmapped objects by learning to exploit the hidden probabilistic model that governs where these objects appear in the environment. The learned policies can generalise to object classes unseen during training by using word vectors that express semantic similarity as representations for object nodes in the graph. Furthermore, we show that the policies generalise to unseen environments with only minimal loss of performance. We demonstrate that pre-training the policy network with a proxy task can significantly speed up learning, improving sample efficiency.},
  link={https://arxiv.org/abs/1909.07376},
  arxiv={1909.07376},
  thumb={suenderhauf19keys.png}
}

@article{rana19navigation,
  title={{Residual Reactive Navigation: Combining Classical and Learned Navigation Strategies For Deployment in Unknown Environments}},
  author={Krishan Rana and Ben Talbot and Michael Milford and Niko S{\"u}nderhauf},
  journal={arXiv preprint arXiv:1909.10972},
  year={2019},
  abstract={In this work we focus on improving the efficiency and generalisation of learned navigation strategies when transferred from its training environment to previously unseen ones. We present an extension of the residual reinforcement learning framework from the robotic manipulation literature and adapt it to the vast and unstructured environments that mobile robots can operate in. The concept is based on learning a residual control effect to add to a typical sub-optimal classical controller in order to close the performance gap, whilst guiding the exploration process during training for improved data efficiency. We exploit this tight coupling and propose a novel deployment strategy, switching Residual Reactive Navigation (sRNN), which yields efficient trajectories whilst probabilistically switching to a classical controller in cases of high policy uncertainty. Our approach achieves improved performance over end-to-end alternatives and can be incorporated as part of a complete navigation stack for cluttered indoor navigation tasks in the real world.},
  link={https://arxiv.org/abs/1909.10972},
  arxiv={1909.10972},
  thumb={rana19navigation.png},
  html={https://github.com/krishanrana/2D_SRRN}
}


@article{Jablonsky18geometric,
  title={{An Orientation Factor for Object-Oriented SLAM}},
  author={Natalie Jablonsky and Michael Milford and Niko S\"underhauf},
  year={2018},
  journal = {{arXiv preprint}},
  abstract = {Current approaches to object-oriented SLAM lack the ability to incorporate prior knowledge of the scene geometry, such as the expected global orientation of objects. We overcome this limitation by proposing a geometric factor that constrains the global orientation of objects in the map, depending on the objects’ semantics. This new geometric factor is a first example of how semantics can inform and improve geometry in object-oriented SLAM. We implement the geometric factor for the recently proposed QuadricSLAM that represents landmarks as dual quadrics. The factor probabilistically models the quadrics’ major axes to be either perpendicular to or aligned with the direction of gravity, depending on their semantic class. Our experiments on simulated and real-world datasets show that using the proposed factors to incorporate prior knowledge improves both the trajectory and landmark quality.},
link={https://arxiv.org/abs/1809.06977},
thumb={jablonsky18geometric.png},
arxiv={1809.06977},
html={http://semanticslam.ai/geometricfactors.html}
}

@article{Lee18zeroshot,
  title={{Zero-shot Sim-to-Real Transfer with Modular Priors}},
  author={Robert Lee and Serena Mou and Vibhavari Dasagi and Jake Bruce and Jürgen Leitner and Niko S\"underhauf},
  year={2018},
  journal = {{arXiv preprint}},
  abstract = {Current end-to-end Reinforcement Learning (RL) approaches are severely limited by restrictively large search spaces and are prone to overfitting to their training environment. This is because in end-to-end RL perception, decision-making and low-level control are all being learned jointly from very sparse reward signals, with little capability of incorporating prior knowledge or existing algorithms. In this work, we propose a novel framework that effectively decouples RL for high-level decision making from low-level perception and control. This allows us to transfer a learned policy from a highly abstract simulation to a real robot without requiring any transfer learning. We therefore coin our approach zero-shot sim-to-real transfer. We successfully demonstrate our approach on the robot manipulation task of object sorting. A key component of our approach is a deep sets encoder that enables us to reinforcement learn the high-level policy based on the variable-length output of a pre-trained object detector, instead of learning from raw pixels. We show that this method can learn effective policies within mere minutes of highly simplified simulation. The learned policies can be directly deployed on a robot without further training, and generalize to variations of the task unseen during training.},
link={https://arxiv.org/abs/1809.07480},
thumb={lee18zeroshot.png},
arxiv={1809.07480}
}
